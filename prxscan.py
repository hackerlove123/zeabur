import requests
import re
import argparse
import time
import os

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}

# C·∫•u h√¨nh Telegram Bot
TELEGRAM_BOT_TOKEN = "7318225955:AAF6ZD3Hxvtj_vDj6fgpW3E3HXfIyzN1LD4"
TELEGRAM_CHAT_ID = "7371969470"

# H√†m g·ª≠i tin nh·∫Øn qua Telegram
def send_telegram_message(message):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
    try:
        response = requests.post(url, data=data)
        if response.status_code == 200:
            print("üì§ Tin nh·∫Øn ƒë√£ g·ª≠i th√†nh c√¥ng.")
        else:
            print(f"‚ö†Ô∏è L·ªói g·ª≠i tin nh·∫Øn Telegram: {response.status_code}")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói k·∫øt n·ªëi t·ªõi Telegram: {e}")

# H√†m ƒë·ªçc danh s√°ch c√°c trang proxy t·ª´ file
def load_proxy_sites(file_path):
    try:
        with open(file_path) as f: return [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        print(f"üö® Kh√¥ng t√¨m th·∫•y file: {file_path}")
        return []

# H√†m qu√©t proxy t·ª´ trang web
def scrape_proxies(site):
    try:
        response = requests.get(site, headers=headers, timeout=7)
        if response.status_code == 200:
            proxies = re.findall(r"\d+\.\d+\.\d+\.\d+:\d+", response.text)
            print(f"\n{'='*50}\nƒêang qu√©t: {site}\nGET {response.status_code}\nS·ªë l∆∞·ª£ng proxy: {len(proxies)}\n{'='*50}")
            return proxies
        return print(f"\n{'='*50}\nƒêang qu√©t: {site}\nGET {response.status_code}\nTh·∫•t b·∫°i\n{'='*50}")
    except requests.exceptions.RequestException as e:
        return print(f"\n{'='*50}\nƒêang qu√©t: {site}\nL·ªói: {e}\n{'='*50}")

# H√†m l∆∞u proxy v√†o file
def save_proxies(proxies, filename="live.txt"):
    with open(filename, "w") as file: file.writelines(f"{proxy}\n" for proxy in proxies)
    return len(proxies)

# H√†m x√≥a b·∫£ng t·ªïng k·∫øt c≈©
def clear_screen(): os.system('cls' if os.name == 'nt' else 'clear')

# H√†m ch√≠nh qu√©t v√† x·ª≠ l√Ω proxy
def main():
    parser = argparse.ArgumentParser(description="Qu√©t proxy t·ª´ c√°c trang web.")
    parser.add_argument("-l", "--list", required=True, help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ch·ª©a danh s√°ch c√°c trang web proxy.")
    args = parser.parse_args()
    
    proxy_sites = load_proxy_sites(args.list)
    if not proxy_sites: return print("‚ö†Ô∏è Danh s√°ch proxy r·ªóng ho·∫∑c kh√¥ng h·ª£p l·ªá.")

    while True:
        clear_screen()  # X√≥a b·∫£ng t·ªïng k·∫øt c≈©
        all_proxies = set()  # L√†m m·ªõi danh s√°ch proxy m·ªói l·∫ßn qu√©t
        message = "üì° K·∫øt qu·∫£ qu√©t proxy:\n"

        for site in proxy_sites:
            proxies = scrape_proxies(site)
            if proxies:
                all_proxies.update(proxies)  # C·∫≠p nh·∫≠t proxy m·ªõi
                message += f"\nƒêang qu√©t: {site}\nS·ªë l∆∞·ª£ng proxy: {len(proxies)}\n{'='*50}"

        if all_proxies:
            proxies_saved = save_proxies(all_proxies)
            message += f"\nüíæ ƒê√£ l∆∞u {proxies_saved} proxy v√†o *live.txt*."
            message += f"\n‚úÖ T·ªïng proxy t√¨m th·∫•y: {len(all_proxies)}"
            print(message)
            send_telegram_message(message)  # G·ª≠i tin nh·∫Øn v·ªÅ Telegram
        else:
            message = "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y proxy h·ª£p l·ªá."
            print(message)
            send_telegram_message(message)  # G·ª≠i tin nh·∫Øn v·ªÅ Telegram
        
        print(f"‚è≥ ƒê·ª£i 5 ph√∫t tr∆∞·ªõc khi qu√©t l·∫°i...")
        time.sleep(150)  # ƒê·ª£i (150 gi√¢y)

if __name__ == "__main__":
    main()
